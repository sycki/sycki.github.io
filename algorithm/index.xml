<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据结构与算法 on 橡果笔记</title>
    <link>http://localhost:1313/algorithm/index.html</link>
    <description>Recent content in 数据结构与算法 on 橡果笔记</description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="http://localhost:1313/algorithm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>http://localhost:1313/algorithm/algorithm-collaborative-filtering.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/algorithm/algorithm-collaborative-filtering.html</guid>
      <description>&lt;h1 id=&#34;推荐算法---协同过滤&#34;&gt;推荐算法 - 协同过滤&lt;a class=&#34;anchor&#34; href=&#34;#%e6%8e%a8%e8%8d%90%e7%ae%97%e6%b3%95---%e5%8d%8f%e5%90%8c%e8%bf%87%e6%bb%a4&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;p&gt;协同过滤是一种推荐算法，它是一种解决特定问题的思路，而非一种固定算法，所以它可以有多种实现，各种实现略有差异，本文将用通俗的方式帮助你了解它的原理，并给出一个应用的实例。&lt;/p&gt;&#xA;&lt;h2 id=&#34;理解协同过滤&#34;&gt;理解协同过滤&lt;a class=&#34;anchor&#34; href=&#34;#%e7%90%86%e8%a7%a3%e5%8d%8f%e5%90%8c%e8%bf%87%e6%bb%a4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;假如我有一个跟我品味相似的朋友，大多数时候，我喜欢听的歌他也喜欢，这时就可以把那些我喜欢的而他没有听过的歌，推荐给他，反之，他也可以推荐给我。 这里有两个关键指标，一个是需要知道我对每首歌的喜欢程度，还有就是哪些人与我品味相似。 图解一下：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;img/algorithm-collaborative-filtering/algorithm-collaborative-filtering_table.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;上表有ABC三人，与XYZ三首歌，数字表示用户给歌曲的评分（满分为10），也表示用户对歌曲的喜欢程度，例如：用户A对歌曲X的喜欢程度为9。而用户A与用户B可以认为是品味相似，因为用户AB同时喜欢歌曲X，且同时不太喜欢歌曲Y。这时就可以将用户A喜欢的歌曲Z推荐给用户B。&lt;/p&gt;&#xA;&lt;h2 id=&#34;计算用户相关性&#34;&gt;计算用户相关性&lt;a class=&#34;anchor&#34; href=&#34;#%e8%ae%a1%e7%ae%97%e7%94%a8%e6%88%b7%e7%9b%b8%e5%85%b3%e6%80%a7&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;关于这个问题，网上大多都提到了“欧几里得距离”以及“皮尔逊相关系数”这两个方法，相信这两种方法的相应实现，网上也能找到一大把，不过我想以另一种方法来说明一下，还是以上面的表为例，我们以每首歌为单为，求出所有用户对每首歌的评价的相似性，如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;所有用户对歌曲X评价的相似性：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;img/algorithm-collaborative-filtering/algorithm-collaborative-filtering_tablex.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;计算规则：用户A对X的评分为9，用户B对X的评分为8，求出它们的差的绝对值，也就是1，值越小相关性越强。依此类推求出剩下人的相关性。灰色部分的值是重覆的，因此略过。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;所有用户对歌曲Y评价的相似性：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;img/algorithm-collaborative-filtering/algorithm-collaborative-filtering_tabley.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;将上面两张表合并，也就是将他们的值合并起来：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;img/algorithm-collaborative-filtering/algorithm-collaborative-filtering_table-sum.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;这张表上的值表示：A与B的相关性最强，B与C其次，A与C相关性则最差。 当然，我们可以将上表中的结果提取出来做个排序，这样当A有了喜欢的新歌时，根据每个用户与A的相关性排序，应优先推荐给B，其次是C。而当C有了喜欢的新歌时，优先推荐给B，其次才是A。&lt;/p&gt;&#xA;&lt;h2 id=&#34;使用spark-mllib中的als算法&#34;&gt;使用Spark MLLib中的ALS算法&lt;a class=&#34;anchor&#34; href=&#34;#%e4%bd%bf%e7%94%a8spark-mllib%e4%b8%ad%e7%9a%84als%e7%ae%97%e6%b3%95&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;上面只是帮助你理解协同过滤的核心思想，而实际的实现有多种，而且也比较复杂，不过在Spark的机器学习库中已经有相应的实现，也就是ALS算法，我们只需提供数据集，可以很容易的使用，下面就来演示一下它的用法。&lt;/p&gt;&#xA;&lt;h3 id=&#34;生成测试数据&#34;&gt;生成测试数据&lt;a class=&#34;anchor&#34; href=&#34;#%e7%94%9f%e6%88%90%e6%b5%8b%e8%af%95%e6%95%b0%e6%8d%ae&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;package com.algorithm.matrix&#xA; &#xA;import scala.util.Random&#xA;import java.io.PrintWriter&#xA; &#xA;/**&#xA; * 此类用来生成一些测试数据并写入到指定的文件中&#xA; */&#xA;object GenFile {&#xA;   &#xA;  //模拟歌手列表&#xA;  val artists = Array(&amp;#34;李健&amp;#34;,&amp;#34;吉克隽逸&amp;#34;,&amp;#34;吴莫愁&amp;#34;,&amp;#34;杨坤&amp;#34;,&amp;#34;宋祖英&amp;#34;,&amp;#34;罗大佑&amp;#34;,&amp;#34;龙梅子&amp;#34;,&#xA;    &amp;#34;水木年华&amp;#34;,&amp;#34;小沈阳&amp;#34;,&amp;#34;谭晶&amp;#34;,&amp;#34;蔡健雅&amp;#34;,&amp;#34;刘佳&amp;#34;,&amp;#34;王蓉&amp;#34;,&amp;#34;黄龄&amp;#34;,&amp;#34;庞麦郎&amp;#34;,&amp;#34;钟汉良&amp;#34;)&#xA;   &#xA;  //模拟用户列表&#xA;  val user = Array(&amp;#34;q&amp;#34;,&amp;#34;w&amp;#34;,&amp;#34;e&amp;#34;,&amp;#34;r&amp;#34;,&amp;#34;t&amp;#34;,&amp;#34;y&amp;#34;,&amp;#34;u&amp;#34;,&amp;#34;i&amp;#34;,&amp;#34;o&amp;#34;,&amp;#34;p&amp;#34;,&amp;#34;a&amp;#34;,&amp;#34;s&amp;#34;)&#xA;   &#xA;  //创建一个随机对象&#xA;  val random = Random&#xA;   &#xA;  /**&#xA;   * 定义一个函数，用随机的的方式模拟出某用户听了某歌手的歌，并给出评分&#xA;   * 生成数据格式为：用户ID，歌手ID，评分&#xA;   */&#xA;  def genLine() = {&#xA;    val ad = artists(random.nextInt(artists.length)).hashCode()&#xA;    val ud = user(random.nextInt(user.length)).hashCode()&#xA;    val count = random.nextInt(30) + 1&#xA;    s&amp;#34;$ud,$ad,$count&amp;#34;&#xA;  }&#xA;   &#xA;  def main(args: Array[String]): Unit = {&#xA;     &#xA;    //创建文件对象&#xA;    val file = new PrintWriter(&amp;#34;D:/Downloads/user_artists.log&amp;#34;)&#xA;     &#xA;    //生成1000条评价，每条为一行，写入文件中&#xA;    for(i &amp;lt;- 0 to 1000){&#xA;      val str = genLine&#xA;      file.println(str)&#xA;    }&#xA;     &#xA;    file.close()&#xA;     &#xA;  }&#xA;   &#xA;}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面代码用来生成一些模拟数据，这个不是必须的，可以用自己的方法得到数据，生成完以后就可以上传到HDFS中，比如： &lt;code&gt;hdfs:///test/user_artists.log&lt;/code&gt; 这个位置。当然只是测试的话也可以放在本地，然后以本地模式启动Spark来运行。&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/algorithm/algorithm-naive-bayes.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/algorithm/algorithm-naive-bayes.html</guid>
      <description>&lt;h1 id=&#34;分类算法---朴素贝叶斯&#34;&gt;分类算法 - 朴素贝叶斯&lt;a class=&#34;anchor&#34; href=&#34;#%e5%88%86%e7%b1%bb%e7%ae%97%e6%b3%95---%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;p&gt;朴素贝叶斯是种简单而有效的分类算法，被应用在很多二元分类器中，那什么叫二元分类？也就是非A即B，假设我现在用朴素贝叶斯算法写一个分类器，然后输入一封邮件，它可以根据特征库来判断这封邮件是不是垃圾邮件。当然，它还可以用来处理多元分类的问题，比如：文章分类、拼写纠正等等。&lt;/p&gt;&#xA;&lt;h2 id=&#34;基本原理&#34;&gt;基本原理&lt;a class=&#34;anchor&#34; href=&#34;#%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;在网上已经有很多关于朴素贝叶斯的介绍了，其中不乏一些讲得深刻而又通俗易懂的文章，本文不准备长篇大论探讨它的数学原理及深层含义，不过基本原理还是得讲一下，先说一下条件概率模型，以下摘抄自wiki：&lt;/p&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;公式：p(C|F1,&amp;hellip;,Fn)&#xA;解释：独立的类别变量C有若干类别，条件依赖于若干特征变量。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;意思是说，在F1,F2,F3&amp;hellip;这些特征发生的情况下，类别C的发生概率，很容易理解。 那么，如果我事先知道类别C发生的情况下，F1,F2,F3&amp;hellip;出现的概率，也就是p(F1,&amp;hellip;,Fn|C)，那么也可以反过来求出p(C|F1,&amp;hellip;,Fn)，这其实就是它基本原理了，以下是贝叶斯公式：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;p(类别1|特征1,特征2,特征3...) = p(特征1,特征2,特征3...|类别1) * p(类别1) / p(特征1,特征2,特征3...)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;解释： p(类别1|特征1,特征2,特征3&amp;hellip;) 表示在特征1、特征2、特征3&amp;hellip;发生的情况下，类别1发生的概率。 p(特征1,特征2,特征3&amp;hellip;|类别1) 表示在类别1发生的情况下，特征1、特征2、特征3&amp;hellip;发生的概率。 p(类别1) 表示类别1在所有类别中出的概率 p(特征1,特征2,特征3&amp;hellip;) 表示特征1,特征2,特征3&amp;hellip;在特征库中出现的概率 重复使用链式法则后，最终可以将公式转换为这样：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;p(类别1|特征1,特征2,特征3...) = p(特征1|类别1) * p(特征2|类别1) * p(特征3|类别1) ...&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这就是朴素贝叶斯公式了。&lt;/p&gt;&#xA;&lt;h2 id=&#34;实现邮件分类器&#34;&gt;实现邮件分类器&lt;a class=&#34;anchor&#34; href=&#34;#%e5%ae%9e%e7%8e%b0%e9%82%ae%e4%bb%b6%e5%88%86%e7%b1%bb%e5%99%a8&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;之前在研究Spark的MLLib时第一次接触到朴素贝叶斯算法（实际上已经是2016年的事了），并动手实现了一个简单的垃圾邮件识别程序，今天重新整理一下，我会在代码中一步一步讲明原理，先说一下实现邮件分类器的步骤：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;收集数据，准备一些正常的邮件和垃圾邮件，将它们放在两个不同的目录中&lt;/li&gt;&#xA;&lt;li&gt;特征提取，要让程序判断一封邮件是不是垃圾邮件，就需要告诉程序，什么是正常邮件，什么是垃圾邮件，这一步叫特征提取，也可以叫做训练集，提取的方法很简单，就是分别计算出正常邮件中与垃圾邮件中所有单词出现的数次及概率，这样我们就有了两个训练集&lt;/li&gt;&#xA;&lt;li&gt;识别邮件，这时需要写一个函数用来接收并识别给定的邮件，其原理也很简单，先将指定的邮件中的所有单词提取出来，然后计算这些单词在两个训练集出现的概率之积即可，这样就得到两个数字，从哪个训练集中计算出的数字大，那这封邮件就属于哪种类型。&lt;/li&gt;&#xA;&lt;li&gt;参数调整，当程序基本实现后，需要对各步骤中的参数进行调整，比如在特征提取时，我去掉了只出现一次或两次的单词，又比如，在识别新邮件时，如果这封邮件中出现了训练集中没有的单词时，应该给定它一个默认的概率值&#xA;下面给出一个实际的例子，在本例中我大概用了三千封历史邮件，分别放在了两个目录中，例子中的数据实在是想不起来在哪下载的，所以请同学们自行收集吧。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;首先是准备数据：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;package com.algorithm.bayes&#xA; &#xA;import org.apache.spark.SparkConf&#xA;import org.apache.spark.SparkContext&#xA;import scala.io.Source&#xA;import java.io.File&#xA;import scala.sys.process.ProcessBuilder.Source&#xA;import scala.collection.mutable.ArrayBuffer&#xA;import scala.collection.mutable.HashMap&#xA; &#xA;/**&#xA; * 利用贝叶斯实现的邮件分类器，提交给Spark执行&#xA; */&#xA;object Classification {&#xA;   &#xA;  def main(args: Array[String]): Unit = {&#xA;     &#xA;    //初始化Spark&#xA;    val conf = new SparkConf().setAppName(this.getClass.getName)&#xA;    val sc = new SparkContext(conf)&#xA;     &#xA;    //该目录内均为正常邮件&#xA;    var easy = &amp;#34;/home/kxdmmr/src/ml-data/Email-data/easy_ham&amp;#34;&#xA;     &#xA;    //该目录内均为垃圾邮件&#xA;    var spam = &amp;#34;/home/kxdmmr/src/ml-data/Email-data/spam&amp;#34;&#xA;     &#xA;...&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后就是创建两个特征库，这个是重中之重：&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/algorithm/algorithm-quick-sort.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/algorithm/algorithm-quick-sort.html</guid>
      <description>&lt;h1 id=&#34;排序算法---快速排序&#34;&gt;排序算法 - 快速排序&lt;a class=&#34;anchor&#34; href=&#34;#%e6%8e%92%e5%ba%8f%e7%ae%97%e6%b3%95---%e5%bf%ab%e9%80%9f%e6%8e%92%e5%ba%8f&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;p&gt;作为排序之王的快速排序法，要理解它很容易，但实现起来又是另外一回事，主要是因为快速排序在实现上是很苛刻的，差之毫厘，谬以千里，如果不是专业研究算法的话，突然哪天要用到还真不一定写的出来，主要是平时用的很少。。&lt;/p&gt;&#xA;&lt;h2 id=&#34;基本原理&#34;&gt;基本原理&lt;a class=&#34;anchor&#34; href=&#34;#%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;给定一个数据集，先从中选出一个元素作为枢钮元，选取枢钮元有多种策略，它对算法的性能影响颇大，目前效果最好的应该是三数中值分割法，三数指的是数组中第一个元素，最后一个元素，和中间那个元素，然后从这三个元素中找出中位数并作为枢钮元&lt;/li&gt;&#xA;&lt;li&gt;将大于枢钮元的元素移动到枢钮元的左边，将小于枢钮元的元素移动到枢钮元的右边&lt;/li&gt;&#xA;&lt;li&gt;这时在枢钮元两边可以看作是两个子数据集，然后对这两个数据集分别进行快速排序，直到子数据集长度为1&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;时间复杂度&#34;&gt;时间复杂度&lt;a class=&#34;anchor&#34; href=&#34;#%e6%97%b6%e9%97%b4%e5%a4%8d%e6%9d%82%e5%ba%a6&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;平均时间为O(N log N)&lt;/li&gt;&#xA;&lt;li&gt;最坏情况为O(N^2)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;实例&#34;&gt;实例&lt;a class=&#34;anchor&#34; href=&#34;#%e5%ae%9e%e4%be%8b&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;static void swap(int [] a,int i,int j){&#xA;    int temp = a[i];&#xA;    a[i] = a[j];&#xA;    a[j] = temp;&#xA;}&#xA;static int partition(int a[],int start,int end){&#xA;    int m = start+(end-start)/2;&#xA;    if(a[start] &amp;gt; a[end])&#xA;        swap(a,start,end);&#xA;    if(a[start] &amp;gt; a[m])&#xA;        swap(a,start,m);&#xA;    if(a[m] &amp;lt; a[end])&#xA;        swap(a,m,end);&#xA; &#xA;    return a[end];&#xA;}&#xA;static void quickSort(int a[],int start,int end){&#xA; &#xA;    if(!(start&amp;lt;end))&#xA;        return;&#xA; &#xA;    int temp = partition(a,start,end);&#xA; &#xA;    int i = start, j = end;&#xA;    while(i &amp;lt; j){&#xA;        while(i &amp;lt; j &amp;amp;&amp;amp; a[i] &amp;lt;= temp)i++;&#xA;        a[j] = a[i];&#xA;        while(i &amp;lt; j &amp;amp;&amp;amp; a[j] &amp;gt;= temp)j--;&#xA;        a[i] = a[j];&#xA;    }&#xA;    a[j] = temp;&#xA; &#xA;    quickSort(a,start,j-1);&#xA;    quickSort(a,j+1,end);&#xA; &#xA;}&#xA; &#xA;public static void quickSort(int[] arr){&#xA;    quickSort(arr, 0, arr.length - 1);&#xA;}&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
  </channel>
</rss>
